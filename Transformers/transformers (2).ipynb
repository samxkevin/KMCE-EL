{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a553327-db02-4b37-a2bd-39ea186fc664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0e047c-b35b-427e-b036-57163e0af744",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_en = \"I love AI .\"\n",
    "sentence_fr = \"J' adore l'IA .\"\n",
    "\n",
    "word_map_en = {\"<pad>\": 0, \"I\": 1, \"love\": 2, \"AI\": 3, \".\": 4}\n",
    "word_map_fr = {\"<pad>\": 0, \"J'\": 1, \"adore\": 2, \"l'IA\": 3, \".\": 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bcf7ed1-139f-4cc7-bbea-8e7b861b1841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence_en,word_map_en):\n",
    "    return torch.tensor([word_map_en[word] for word in sentence_en.split()])\n",
    "\n",
    "# def tokenize(sentence, word_map, max_length):\n",
    "#     tokens = [word_map[word] for word in sentence.split()]\n",
    "#     while len(tokens) < max_length:  \n",
    "#         tokens.append(word_map[\"<pad>\"])  # Padding to fixed length\n",
    "#     return torch.tensor(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7fb4cb3-1ca1-4d52-a609-0854b756e4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = tokenize(sentence_en, word_map_en).unsqueeze(0)\n",
    "target_tensor = tokenize(sentence_fr, word_map_fr).unsqueeze(0)\n",
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98ee803d-6bce-4534-9c0f-a3f1a95736b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0],\n",
       "        [   1],\n",
       "        [   2],\n",
       "        ...,\n",
       "        [4997],\n",
       "        [4998],\n",
       "        [4999]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0,5000).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "746ef7de-428f-467c-a115-28b77980c5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=8, out_features=8, bias=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Linear(8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c67d5c35-0c06-4b67-83f1-39aa4068177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,d_model,max_len = 5000):\n",
    "        super(PositionalEncoding,self).__init__()\n",
    "        self.encoding = torch.zeros(max_len,d_model)\n",
    "        position = torch.arange(0,max_len,dtype = torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0,d_model,2).float() * -(torch.log(torch.tensor(10000.0))/d_model))\n",
    "        self.encoding[:,0::2] = torch.sin(position*div_term)\n",
    "        self.encoding[:,1::2] = torch.cos(position*div_term)\n",
    "        self.encoding = self.encoding.unsqueeze(0)\n",
    "    def forward(self,X):\n",
    "        return X + (self.encoding[:,:X.size(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7deec00d-01b7-4dc1-a1c8-68f2651bc0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // num_heads\n",
    "        self.d_v = d_model // num_heads\n",
    "\n",
    "        self.query = nn.Linear(d_model, d_model)\n",
    "        self.key = nn.Linear(d_model, d_model)\n",
    "        self.value = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.fc = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "\n",
    "        q = self.query(x).view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        k = self.key(x).view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        v = self.value(x).view(batch_size, seq_len, self.num_heads, self.d_v).transpose(1, 2)\n",
    "\n",
    "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / torch.sqrt(torch.tensor(self.d_k, dtype=torch.float))\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, float('-inf'))  # Ensure mask matches input length\n",
    "        attn_weights = F.softmax(attn_scores, dim=-1)\n",
    "\n",
    "        attention_output = torch.matmul(attn_weights, v).transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_model)\n",
    "        output = self.fc(attention_output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18203149-a0c9-45c4-b7fb-800c0f971f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):#attention accross global sequences:, Learning rate scheduler, dropout, residual connections,\n",
    "    def __init__(self, d_model, d_ff=512):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)  \n",
    "        self.fc2 = nn.Linear(d_ff, d_model)  \n",
    "        self.relu = nn.ReLU()  \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a777fb71-988b-47c0-afd2-6ee4f376a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff=512):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        self.multihead_attn = MultiHeadAttention(d_model, num_heads) \n",
    "        self.feedforward = FeedForward(d_model, d_ff)\n",
    "        \n",
    "        self.norm1 = nn.LayerNorm(d_model) \n",
    "        self.norm2 = nn.LayerNorm(d_model)  \n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "       \n",
    "        attn_output = self.multihead_attn(x, mask)\n",
    "        x = self.norm1(x + attn_output) \n",
    "        \n",
    "        ffn_output = self.feedforward(x)\n",
    "        x = self.norm2(x + ffn_output) \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "996a7746-e3f8-4489-9d24-c6d746d4006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff=512):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.masked_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feedforward = FeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, enc_output, tgt_mask=None, src_mask=None):\n",
    "        attn_output = self.masked_attn(x,tgt_mask)\n",
    "        x = self.norm1(x + attn_output)\n",
    "        attn_output = self.enc_dec_attn(x,src_mask)\n",
    "        x = self.norm2(x + attn_output)\n",
    "        ffn_output = self.feedforward(x)\n",
    "        x = self.norm3(x + ffn_output)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a6ebea-9e44-46df-8146-66e6ccec3df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self,vocab_size,d_model,num_heads,num_encoder_layers,num_decoder_layers,max_len = 5000):\n",
    "        super(Transformer,self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size,d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model,max_len)\n",
    "        self.encoder_layers  = nn.ModuleList([EncoderLayer(d_model,num_heads) for _ in range(num_encoder_layers)])\n",
    "        self.decoder_layers  = nn.ModuleList([DecoderLayer(d_model,num_heads) for _ in range(num_decoder_layers)])\n",
    "        self.fc_out = nn.Linear(d_model,vocab_size)\n",
    "    def forward(self,src,tgt,tgt_mask=None):\n",
    "        src = self.pos_encoder(self.embedding(src))\n",
    "        tgt = self.pos_encoder(self.embedding(tgt))\n",
    "        encoder_output = src\n",
    "        for i in self.encoder_layers:\n",
    "            encoder_output = i(encoder_output)\n",
    "        decoder_output = tgt\n",
    "        for i in self.decoder_layers:\n",
    "            decoder_output = i(decoder_output,encoder_output,tgt_mask = tgt_mask)\n",
    "        output = self.fc_out(decoder_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e1087a0-1453-4cef-ab0e-9bd633b12b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(input_sequence,word_map_en,word_map_fr,transformer):\n",
    "    input_tensor = tokenize(input_sequence,word_map_en).unsqueeze(0)\n",
    "    tgt_mask = torch.tril(torch.ones((input_tensor.size(1),input_tensor.size(1)))).unsqueeze(0).unsqueeze(0)\n",
    "    target_tensor = torch.zeros((1,input_tensor.size(1)),dtype = torch.long)\n",
    "    output = transformer(input_tensor,target_tensor,tgt_mask)\n",
    "    softmax_output = F.softmax(output,dim = -1)\n",
    "    predicted_tokens = torch.argmax(softmax_output,dim=-1)\n",
    "    reverse_word_map_fr = {v:k for k,v in word_map_fr.items()}\n",
    "    translated_sentence = [reverse_word_map_fr[token.item()] for token in predicted_tokens[0] if token!=0]\n",
    "    return \" \".join(translated_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bd9b124-b359-4cca-a86d-705526ba3fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size_en = len(word_map_en)\n",
    "vocab_size_fr = len(word_map_fr)\n",
    "d_model = 128\n",
    "num_heads = 8\n",
    "num_encoder_layers = 2\n",
    "num_decoder_layers = 2\n",
    "transformer = Transformer(vocab_size_en,d_model,num_heads,num_encoder_layers,num_decoder_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "76f635f9-fb87-4c02-8b37-1793b39f6864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"J'\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"I\", word_map_en,word_map_fr,transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a009588-b42a-4474-826d-ba92aa8675f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated Sentence: J'\n"
     ]
    }
   ],
   "source": [
    "translated = translate(\"I love AI .\", word_map_en, word_map_fr, transformer)\n",
    "print(\"Translated Sentence:\", translated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
